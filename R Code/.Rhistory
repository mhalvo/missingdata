missing="ML") # missing="ML" is the piece to add
summary(fit1.ml)
summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_f))
(p1 <- ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_m), color="purple", size=11) +
geom_point(aes(y=drinks_s), color="blue", size=9) +
geom_point(aes(y=drinks_z), color="light blue", size=7) +
geom_point(aes(y=drinks_l), color="white", size=5) +
geom_point(aes(y=drinks), color="black", size=13)) +
ylim(-1,5)
(p1 <- ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_m), color="purple", size=11) +
geom_point(aes(y=drinks_s), color="blue", size=9) +
geom_point(aes(y=drinks_z), color="light blue", size=7) +
geom_point(aes(y=drinks_l), color="white", size=5) +
geom_point(aes(y=drinks), color="black", size=13) +
ylim(-1,5))
(p1 <- ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_m), color="purple", size=11) +
geom_point(aes(y=drinks_s), color="blue", size=9) +
geom_point(aes(y=drinks_z), color="light blue", size=7) +
geom_point(aes(y=drinks_l), color="white", size=5) +
geom_point(aes(y=drinks), color="black", size=13) +
ylim(-0.5,4.5))
(p1 <- ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_m), color="purple", size=11) +
geom_point(aes(y=drinks_s), color="blue", size=9) +
geom_point(aes(y=drinks_z), color="light blue", size=7) +
geom_point(aes(y=drinks_l), color="white", size=5) +
geom_point(aes(y=drinks), color="black", size=13) +
ylim(-0.5,4.5))
(p1 <- ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_m), color="purple", size=11) +
geom_point(aes(y=drinks_s), color="blue", size=9) +
geom_point(aes(y=drinks_z), color="light blue", size=7) +
geom_point(aes(y=drinks_l), color="white", size=5) +
geom_point(aes(y=drinks), color="black", size=13) +
ylim(-1,5))
(p1 <- ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_m), color="purple", size=11) +
geom_point(aes(y=drinks_s), color="blue", size=9) +
geom_point(aes(y=drinks_z), color="light blue", size=7) +
geom_point(aes(y=drinks_l), color="white", size=5) +
geom_point(aes(y=drinks), color="black", size=13) +
ylim(0,5))
(p2 <- p1 +
geom_hline(aes(yintercept=1.75), color="purple") +
geom_hline(aes(yintercept=2), color="blue") +
geom_hline(aes(yintercept=0), color="light blue"))
(p2 +
geom_smooth(aes(y=drinks), method=lm, color="black", se=F))
(ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_simp), color="orange", size=11) +
geom_point(aes(y=drinks), color="black", size=13) +
geom_smooth(aes(y=drinks), method=lm, color="black", se=F) +
ylim(0,5))
(ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks), color="black", size=13) +
geom_smooth(aes(y=drinks), method=lm, color="black", se=F) +
geom_abline(intercept=-.50, slope=.25) +
geom_abline(intercept=-.40, slope=.25) +
geom_abline(intercept=-.50, slope=.3) +
geom_abline(intercept=-.45, slope=.35) +
ylim(0,5))
##############################
# Missing Data Workshop      #
#   for UW Graduate Students #
##############################
# Max Halvorson #
#  9/20/18      #
#################
library('tidyverse')
rm(list=ls())
set.seed(1337)
setwd('C:/Users/Max/Dropbox/Missing Data Workshop/R Code')
alc <- data.frame(drinks=c(0,3,NA,4,2,NA,1,NA,0,4,NA,0),
drinks_m=c(0,3,1.75,4,2,1.75,1,1.75,0,4,1.75,0),
drinks_s=c(0,3,2,4,2,2,1,2,0,4,2,0),
drinks_z=c(0,3,0,4,2,0,1,0,0,4,0,0),
drinks_l=c(0,3,1,4,2,3,1,2,0,4,0,0))
(p0 <- ggplot(data=alc) +
geom_histogram(aes(x=drinks), fill="black") +
geom_histogram(aes(x=drinks_m), fill="purple") +
geom_histogram(aes(x=drinks_s), fill="blue") +
geom_histogram(aes(x=drinks_z), fill="light blue") +
geom_histogram(aes(x=drinks_l), fill="white"))
alc$exams <- round(alc$drinks/.3 + rnorm(12,0,1) + 2,0)
alc$exams[c(3,6,8,11)] <- c(2,6,9,1)
alc$drinks_simp <- alc$drinks
B <- coef(lm(alc$drinks ~ alc$exams))
alc$drinks_simp[c(3,6,8,11)] <- B[1] + B[2]*alc$exams[c(3,6,8,11)]
psych::describe(alc)
(p1 <- ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_m), color="purple", size=11) +
geom_point(aes(y=drinks_s), color="blue", size=9) +
geom_point(aes(y=drinks_z), color="light blue", size=7) +
geom_point(aes(y=drinks_l), color="white", size=5) +
geom_point(aes(y=drinks), color="black", size=13) +
ylim(0,5))
(p2 <- p1 +
geom_hline(aes(yintercept=1.75), color="purple") +
geom_hline(aes(yintercept=2), color="blue") +
geom_hline(aes(yintercept=0), color="light blue"))
(p2 +
geom_smooth(aes(y=drinks), method=lm, color="black", se=F))
(ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_simp), color="orange", size=11) +
geom_point(aes(y=drinks), color="black", size=13) +
geom_smooth(aes(y=drinks), method=lm, color="black", se=F) +
ylim(0,5))
(ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks), color="black", size=13) +
geom_smooth(aes(y=drinks), method=lm, color="black", se=F) +
geom_abline(intercept=-.50, slope=.25) +
geom_abline(intercept=-.40, slope=.25) +
geom_abline(intercept=-.50, slope=.3) +
geom_abline(intercept=-.45, slope=.35) +
ylim(0,5))
(p1 <- ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_m), color="purple", size=11) +
geom_point(aes(y=drinks_s), color="blue", size=9) +
geom_point(aes(y=drinks_z), color="light blue", size=7) +
geom_point(aes(y=drinks_l), color="white", size=5) +
geom_point(aes(y=drinks), color="black", size=13) +
ylim(0,5) +
ylab("drinks"))
(p1 <- ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_m), color="purple", size=11) +
geom_point(aes(y=drinks_s), color="blue", size=9) +
geom_point(aes(y=drinks_z), color="light blue", size=7) +
geom_point(aes(y=drinks_l), color="white", size=5) +
geom_point(aes(y=drinks), color="black", size=13) +
ylim(0,5) +
ylab("drinks"))
(p2 <- p1 +
geom_hline(aes(yintercept=1.75), color="purple") +
geom_hline(aes(yintercept=2), color="blue") +
geom_hline(aes(yintercept=0), color="light blue"))
(p2 +
geom_smooth(aes(y=drinks), method=lm, color="black", se=F))
(ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks_simp), color="orange", size=11) +
geom_point(aes(y=drinks), color="black", size=13) +
geom_smooth(aes(y=drinks), method=lm, color="black", se=F) +
ylim(0,5) +
ylab("drinks"))
(ggplot(aes(x=exams), data=alc) +
geom_point(aes(y=drinks), color="black", size=13) +
geom_smooth(aes(y=drinks), method=lm, color="black", se=F) +
geom_abline(intercept=-.50, slope=.25) +
geom_abline(intercept=-.40, slope=.25) +
geom_abline(intercept=-.50, slope=.3) +
geom_abline(intercept=-.45, slope=.35) +
ylim(0,5) +
ylab("drinks"))
dnba_f <- dnba_m
result <- summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_f))
result
##############################
# Missing Data Workshop      #
#   for UW Graduate Students #
##############################
# Max Halvorson #
#  9/20/18      #
#########################
# Data Analysis Example #
#########################
###
################################
# Multiple Imputation Examples #
################################
###
library('tidyverse')
library('lattice')
library('mice')
### Data load and cleaning ###
dnba <- as.tibble(read.csv('https://raw.githubusercontent.com/mhalvo/teaching/master/NBAcombine.csv'))
dnba$PID <- 1:1000
dnba <-  select(dnba,
Name, PID, Height, Weight, Vertical, T.Q..Spring,
L.A.T., NSeasons)
dnba_m <- select(dnba, -Name) %>% replace(., . == 0, NA)
dnba_m$NSeasons <- replace(dnba_m$NSeasons, is.na(dnba_m$NSeasons), 0)
#####################
# Impute using MICE #
#####################
print(dnba_m, n=30)
md.pattern(dnba_m) # check on the missing data pattern
imp_dnba_m <- mice(dnba_m, # run imputation
m=5,
maxit=50,
method=meth,
seed=1337)
plot(imp_dnba_m) # examine convergence
### What to look for in convergence
init <- mice(dnba_m, maxit=0) # initialize/check some parameters
init
# Discuss Predictor and Imputation lists
### A note on predictive mean matching
### FCS: "Fully conditional specification"
densityplot(imp_dnba_m) # anything look totally off?
imp1 <- mice::complete(imp_dnba_m, 1)
imp1$Name <- dnba$Name
select(imp1, Name, Height)[which(dnba$Height==0),]
# Check some imputed height values for fun: a few actual heights - Nick Collison: 82, Chris Bosh: 83, Sasha Vujacic: 79
fit <- with(imp_dnba_m, lm(NSeasons ~ Height + Weight + T.Q..Spring)) # summarize results
pool.fit <- pool(fit)
summary(pool.fit)
summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_m))
###
# Read these before running your own analyses - nice code snippets and
#   help in decision-making
#
# http://www.gerkovink.com/miceVignettes/
###
### Note: Under the hood, mice is pooling estimates with the method described in Baraldi & Enders, 2010. We can do this manually if we want a sanity check.
B0s <- sapply(fit$analyses, function(x) {
x$coef[1]})
B0bar <- mean(B0s)
summ <- lapply(fit$analyses, function(x) {
summary(x)})
VW0 <- sapply(summ, function(x) { # within-imputation variance
x$coef[1,2]}) %>% .^2 %>% mean
VB0 <- sum((B0s-B0bar)^2) / (5-1)
poolSEB0 <- sqrt(VW0 + VB0 + VB0/5)
B0bar
poolSEB0
summary(pool.fit)
###################
# Impute in BLIMP #
###################
### Export datasets to BLIMP ###
dnba_b <- select(dnba, -Name) %>% replace(., .==0, -9999)
write.table(dnba_b, file="dnba_b.csv", sep=",", row.names=F, col.names=F)
### Impute in BLIMP - BLIMP has PSR and monitors convergence
# Analyze in your software of choice
### In this case, analyze in MPlus. I'll show my actual MPlus code here to demo data flow
###
# Read this concise manual when running your own analyses - nice
#   help in decision-making and succinct description of options
#
# http://www.appliedmissingdata.com/blimpuserguide-5.pdf
###
#########################
# Notes and Comparisons #
#########################
# MICE can handle multilevel data (but it's confusing)
# BLIMP is designed to multilevel data intuitively
# MICE wants NA for missing data
# BLIMP wants numeric values (I use -9999)
# MICE imputes observations with NO data
# BLIMP does not impute observations with NO data
dnba[c(375,616),]
imp1[c(375,616),]
mice::complete(imp_dnba_m, 2)[c(375,616),]
# Yi Jianlian is 6'11, 243. MICE imputes 6'4.5", 194.2. If nothing else, remember that I am not Yi Jianlian
###
################
# FIML Example #
################
###
library('lavaan')
library('semPlot')
### Data load and cleaning ###
dnba_f <- dnba_m
print(dnba_f, n=50)
###############################
# Specify models using lavaan # Did you know lavaan is an acronym?
###############################
model1 <- '
#betas
NSeasons ~ Height + Weight + T.Q..Spring
'
fit1 <- sem(model1,
data=dnba_f,
fixed.x=F)
summary(fit1, fit.measures=T, standardized=F, rsquare=T)
summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_f))
fit1.ml <- sem(model1,
data=dnba_m,
fixed.x=F,
missing="ML") # missing="ML" is the piece to add
summary(fit1.ml)
summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_f))
###################################
# Comparison across the 3 methods #
###################################
result <- summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_f))
result.mice
result.blimp
result.fiml
result
result$coefficients
result.mice <- summary(pool.fit)
pool
init$method
meth <- init$method
dnba_b <- select(dnba, -Name) %>% replace(., .==0, -9999)
write.table(dnba_b, file="dnba_b.csv", sep=",", row.names=F, col.names=F)
dnba_b
dnba_b$NSeasons <- replace(dnba_b$NSeasons, is.na(dnba_b$NSeasons), 0)
write.table(dnba_b, file="dnba_b.csv", sep=",", row.names=F, col.names=F)
dnba_b
replace(dnba_b$NSeasons, is.na(dnba_b$NSeasons), 0)
dnba_b$NSeasons <- replace(dnba_b$NSeasons, -9999, 0)
dnba_b
dnba_b <- select(dnba, -Name) %>% replace(., .==0, -9999)
dnba_b$NSeasons <- replace(dnba_b$NSeasons, ==-9999, 0)
dnba_b
dnba_b$NSeasons <- replace(dnba_b$NSeasons, dnba_b$NSeasons==-9999, 0)
dnba_b
write.table(dnba_b, file="dnba_b.csv", sep=",", row.names=F, col.names=F)
dnba_b
imp_dnba_b <- read.csv(file='imputed_dnba_b.csv', header=F)
imp_dnba_b
names(imp_dnba_b) <- c("imp", names(dnba_b))
imp_dnba_b
imp_dnba_b <- as.tibble(read.csv(file='imputed_dnba_b.csv', header=F))
names(imp_dnba_b) <- c("imp", names(dnba_b))
imp_dnba_b
result.mice <- summary(pool.fit)
imp_dnba_m <- mice(dnba_m, # run imputation
m=5,
maxit=50,
method=meth,
seed=1337)
# Discuss Predictor and Imputation lists
### A note on predictive mean matching
### FCS: "Fully conditional specification"
### 4) Check out our result
plot(imp_dnba_m) # examine convergence
densityplot(imp_dnba_m) # anything look totally off?
imp1 <- mice::complete(imp_dnba_m, 1)
imp1$Name <- dnba$Name
select(imp1, Name, Height)[which(dnba$Height==0),] # data checking is always key!
# Check some imputed height values for fun: a few actual heights - Nick Collison: 82, Chris Bosh: 83, Sasha Vujacic: 79
### 5) Analyze/summarize results
fit <- with(imp_dnba_m, lm(NSeasons ~ Height + Weight + T.Q..Spring)) # summarize results
pool.fit <- pool(fit)
summary(pool.fit)
summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_m))
result.mice <- summary(pool.fit)
result
result.mice
result.fiml <- summary(fit1.ml)
result.fiml
result.fiml <- summary(fit1.ml)
result.fiml
summary(fit1.ml)$Regressions
summary(fit1.ml)$Ra
imp_dnba_b
fit_m <- with(imp_dnba_m, lm(NSeasons ~ Height + Weight + T.Q..Spring)) # summarize results
fit_m
str(fit_m)
ls(fit_m)
fit_m$analyses
fit_m
ls(fit_m)
fit_m$call
fit_m$call1
fit_m$nmis
for(i in 1:5) {
fit_b[[i]] <- select(imp_dnba_b, imp==i)
}
imp_dnba_b
imp_dnba_b$imp
for(i in 1:5) {
fit_b[[i]] <- select(imp_dnba_b, imp==i)
}
fit_b <- list()
for(i in 1:5) {
fit_b[[i]] <- filter(imp_dnba_b, imp==i)
}
fit_b
imps_b <- list()
for(i in 1:5) {
fit_b[[i]] <- filter(imp_dnba_b, imp==i)
}
imps_b[[i]] <- filter(imp_dnba_b, imp==i)
imps_b <- list()
for(i in 1:5) {
imps_b[[i]] <- filter(imp_dnba_b, imp==i)
}
sapply(imps_b, function(x) {
lm(NSeasons ~ Height + Weight + T.Q..Spring, data=x)
})
sapply(imps_b, function(x) {
summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=x))
})
lapply(imps_b, function(x) {
summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=x))
})
fit_b<- lapply(imps_b, function(x) {
summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=x))
})
fit_b <- lapply(imps_b, function(x) {
summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=x))
})
fit_b
sapply(fit_b, function(x) {
x$coef[1]
}
###
# Read this concise manual when running your own analyses - nice
#   help in decision-making and succinct description of options
#
# http://www.appliedmissingdata.com/blimpuserguide-5.pdf
###
#########################
# Notes and Comparisons #
#########################
# MICE can handle multilevel data (but it's confusing)
# BLIMP is designed to multilevel data intuitively
# MICE wants NA for missing data
# BLIMP wants numeric values (I use -9999)
# MICE imputes observations with NO valid data
# BLIMP does not impute observations with NO data
# BOTH will impute data for observations with even ONE value
dnba[c(375,616),]
imp1[c(375,616),]
mice::complete(imp_dnba_m, 2)[c(375,616),]
# Yi Jianlian is 6'11, 243. MICE imputes 6'4.5", 194.2. If nothing else, remember that I am not Yi Jianlian
###
################
# FIML Example #
################
###
library('lavaan')
library('semPlot')
### Data load and cleaning ###
dnba_f <- dnba_m
print(dnba_f, n=50)
###############################
# Specify models using lavaan # Did you know lavaan is an acronym?
###############################
model1 <- '
#betas
NSeasons ~ Height + Weight + T.Q..Spring
'
fit1 <- sem(model1,
data=dnba_f,
fixed.x=F)
summary(fit1, fit.measures=T, standardized=F, rsquare=T)
summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_f))
fit1.ml <- sem(model1,
data=dnba_m,
fixed.x=F,
missing="ML") # missing="ML" is the piece to add
summary(fit1.ml)
summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_f))
###################################
# Comparison across the 3 methods #
###################################
result <- summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_f))
result.mice <- summary(pool.fit)
result.blimp <- summary()
result.fiml <- summary(fit1.ml)
result$coefficients
sapply(fit_b, function(x) {
x$coef[1]
})
fit_b
sapply(fit_b, function(x) {
x$coef[,1]
})
Bs <- sapply(fit_b, function(x) {
x$coef[,1]  %>% rowMeans
})
Bs <- sapply(fit_b, function(x) {
x$coef[,1]
})
rowMeans(Bs)
mean(6.17,4.58,7.31,6.63,8.00)
mean(6.537,4.58,7.31,6.63,8.00)
mean(c(6.17,4.58,7.31,6.63,8.00))
sapply(fit_b, function(x) {
x$coef[,2]})
SEs <- sapply(fit_b, function(x) {
x$coef[,2]})
SEs^2
4.173^2
.0607^2
mean(SEs^2)
rowMeans(SEs^2)
Bs-pooled_Bs
Bs <- sapply(fit_b, function(x) {
x$coef[,1]
})
pooled_Bs <- rowMeans(Bs)
Bs-pooled_Bs
rowMeans(Bs-pooled_Bs)
(Bs-pooled_Bs)^2
VBs <- rowMeans((Bs-pooled_Bs)^2)
sqrt(VWs + VBs + VBs/5)
VWs <- rowMeans(SEs^2)
VBs <- rowMeans((Bs-pooled_Bs)^2)
pooled_SEs <- sqrt(VWs + VBs + VBs/5)
pooled_SEs
pooled_Bs
pooled_SEs
result
imps_b
sapply(imps_b, function(x) select(x, PID==c(375,616)))
sapply(imps_b, function(x) filter(x, PID==c(375,616)))
lapply(imps_b, function(x) filter(x, PID==c(375,616)))
cbind(pooled_Bs, pooled_SEs)
result.mice
result$coefficients
result <- summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_f))$coef
(result <- summary(lm(NSeasons ~ Height + Weight + T.Q..Spring, data=dnba_f))$coef)
(result.mice <- summary(pool.fit))
(result.blimp <- cbind(pooled_Bs, pooled_SEs))
